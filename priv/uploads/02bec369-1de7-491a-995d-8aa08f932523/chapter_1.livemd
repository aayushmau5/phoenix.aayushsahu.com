# Chapter 1

```elixir
Mix.install([
  {:axon, "~> 0.5.1"},
  {:nx, "~> 0.5.3"},
  {:kino, "~> 0.10.0"},
  {:explorer, "~> 0.5"}
])
```

## Section

### Two types of ML tasks

* Classification
* Regression

### SMART approach

Specific, Measurable, Achievable, Relevant, and Time-bound. For defining your tasks.

### ML is defined as

"A computer pro-gram is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks T, as measured by P improves with experiences E."

* Task
* Performance measure
* Experience

### Learning

Improving from experience.

* Supervise learning
* Unsupervised learning

#### Supervised learning

Data and its "answer" is already available and the model just checks how close to the answer it is.

#### Unsupervised learning

Only data. Unsupervised models learn properties of input data.

The collection of experiences your model learns from is called the **training set**.

<!-- livebook:{"break_markdown":true} -->

?? Reinforcement learning

Multi-dimensional arrays -> Tensors in Nx

> Nx is the common language of data spoken
> by every library in the Nx ecosystem.

> DataFrames are two-dimensional, tabular data structures.

We will use explorer to conduct data analysis, preprocessing, validation, etc.

## Explorer

```elixir
require Explorer.DataFrame, as: DF
```

```elixir
iris = Explorer.Datasets.iris()
```

```elixir
cols = ~w(sepal_width sepal_length petal_length petal_width)

normalized_iris =
  DF.mutate(
    iris,
    for col <- across(^cols) do
      {col.name, (col - mean(col)) / variance(col)}
    end
  )

shuffled_normalized_iris = DF.shuffle(normalized_iris)
```

```elixir
train_df = DF.slice(shuffled_normalized_iris, 0..119)
test_df = DF.slice(shuffled_normalized_iris, 120..149)

train_df["species"] |> Explorer.Series.cast(:category)
```

Getting the data into a format that the model will understand.

`Nx.Tensor` -> Common language spoken by all of the libraries in the Nx ecosystem.
This means, converting the data into a tensor or a **tensor-compatible** format.

Categorial variable -> either integer or one-hot encoding.

**One-hot encoding:** A tensor. Either 0(off) or 1(on).

```elixir
# feature_columns = [
#   "sepal_length",
#   "sepal_width",
#   "petal_length",
#   "petal_width"
# ]

# label_column = "species"

# # extracting the feature columns
# x_train = Nx.stack(train_df[feature_columns], axis: 1)

# train_categories =
#   train_df["species"]
#   |> Explorer.Series.cast(:category)

# y_train =
#   train_categories
#   |> Nx.stack(axis: -1)
#   # hot encoding
#   |> Nx.equal(Nx.iota({1, 3}, axis: -1))

# # extracting the feature columns
# x_test = Nx.stack(test_df[feature_columns], axis: 1)

# test_categories =
#   test_df["species"]
#   |> Explorer.Series.cast(:category)

# y_test =
#   test_categories
#   |> Nx.stack(axis: -1)
#   |> Nx.equal(Nx.iota({1, 3}, axis: -1))

feature_columns = ["sepal_length", "sepal_width", "petal_length", "petal_width"]
label_column = "species"

x_all = Nx.stack(shuffled_normalized_iris[feature_columns], axis: 1)

y_all =
  shuffled_normalized_iris[label_column]
  |> Explorer.Series.cast(:category)
  |> Nx.stack(axis: -1)
  |> Nx.equal(Nx.iota({1, 3}, axis: -1))

x_train = x_all[0..119]
x_test = x_all[120..149]

y_train = y_all[0..119]
y_test = y_all[120..149]
```

## Training

Using `Axon`

1. Define the model
2. Create an input pipeline
3. Declare and run the training loop

### Model

<!-- livebook:{"break_markdown":true} -->

What is `Axon.dense`?

3 -> Three probabilites

`activation` -> `:softmax`

```elixir
model =
  Axon.input("iris_features")
  # 3 represent probabilites here
  |> Axon.dense(3, activation: :softmax)
```

```elixir
{x_train, y_train}
```

```elixir
Axon.Display.as_graph(model, Nx.template({1, 4}, :f32))
```

```elixir
data_stream = Stream.repeatedly(fn -> {x_train, y_train} end)
```

Training the model with gradient descent using `Axon.Loop` API.

The loop:

1. Grab input from input pipeline
2. Make predictions from inputs
3. Determine how good the predictions were
4. Update the model based on prediction goodness
5. Repeat

A single loop -> a single iteration

Group of multiple iterations -> a single epoch.

> An epoch in machine learning means one complete pass of the training dataset through the algorithm.

```elixir
trained_model_state =
  model
  |> Axon.Loop.trainer(:categorical_cross_entropy, :sgd)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(data_stream, %{}, iterations: 500, epochs: 10)
```

```elixir
data = [{x_test, y_test}]

model
|> Axon.Loop.evaluator()
|> Axon.Loop.metric(:accuracy)
|> Axon.Loop.run(data, trained_model_state)
```
